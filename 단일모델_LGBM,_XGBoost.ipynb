{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alscop/ESAA-25-2/blob/main/%EB%8B%A8%EC%9D%BC%EB%AA%A8%EB%8D%B8_LGBM%2C_XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-uvbvagOeNH",
        "outputId": "5fc8d151-b092-4de1-ad9d-2b55ab4aff02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-nanum is already the newest version (20200506-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 12 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm -rf ~/.cache/matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "train = pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "wM2YheLBOjOU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATE_COL   = '영업일자'\n",
        "TARGET_COL = '매출수량'\n",
        "KEY_COLS   = ['영업장명', '메뉴명']\n",
        "\n",
        "# 첫번째 '_' 기준으로 분리\n",
        "train[KEY_COLS] = train['영업장명_메뉴명'].str.split('_', n=1, expand=True)"
      ],
      "metadata": {
        "id": "46gVK44jOsM7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. [가장 중요] 날짜 데이터 형식 변환을 제일 먼저 수행해야 합니다.\n",
        "train['영업일자'] = pd.to_datetime(train['영업일자'])\n",
        "\n",
        "# 2. 기본 날짜 피처 추출 (이제 .dt 접근자 사용 가능)\n",
        "train['요일'] = train['영업일자'].dt.dayofweek\n",
        "train['연도'] = train['영업일자'].dt.year\n",
        "train['월'] = train['영업일자'].dt.month\n",
        "train['일'] = train['영업일자'].dt.day\n",
        "train['주'] = train['영업일자'].dt.isocalendar().week.astype(int)\n",
        "\n",
        "# 3. 주말 여부 생성\n",
        "# (질문자님의 의도대로 금(4), 토(5), 일(6)을 주말로 설정)\n",
        "train['주말여부'] = (train['요일'] >= 4).map({True: '주말', False: '주중'})\n",
        "\n",
        "# 4. 공휴일 설정 (양력 - 매년 고정)\n",
        "holis = ['01-01', '03-01', '05-05', '06-06', '08-15', '10-03', '10-09', '12-25']\n",
        "train['공휴일여부'] = train['영업일자'].dt.strftime('%m-%d').isin(holis).astype(int)\n",
        "\n",
        "# 5. 음력 공휴일 설정 (설날, 추석 등 - 변동 날짜)\n",
        "lunar_holidays = [\n",
        "    '2023-01-21', '2023-01-22', '2023-01-23',\n",
        "    '2023-09-28', '2023-09-29', '2023-09-30',\n",
        "    '2024-02-09', '2024-02-10', '2024-02-11',\n",
        "]\n",
        "train['음력공휴일여부'] = train['영업일자'].dt.strftime('%Y-%m-%d').isin(lunar_holidays).astype(int)\n",
        "\n",
        "# 6. 대체 및 기타 공휴일 설정 (선거일 등)\n",
        "substitute_holidays = [\n",
        "    '2023-01-24', '2023-05-29', '2023-10-02',\n",
        "    '2024-02-12', '2024-04-10', '2024-05-06'\n",
        "]\n",
        "train['대체공휴일여부'] = train['영업일자'].dt.strftime('%Y-%m-%d').isin(substitute_holidays).astype(int)\n",
        "\n",
        "# 7. 전체 공휴일 통합 (하나라도 해당하면 1)\n",
        "train['전체공휴일여부'] = ((train['공휴일여부'] == 1) |\n",
        "                         (train['음력공휴일여부'] == 1) |\n",
        "                         (train['대체공휴일여부'] == 1)).astype(int)\n",
        "\n",
        "# 결과 확인\n",
        "print(train[['영업일자', '요일', '주말여부', '전체공휴일여부']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NMJ2wRHPG5L",
        "outputId": "6a168ce0-4216-4c90-a19c-2df18c93165b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        영업일자  요일 주말여부  전체공휴일여부\n",
            "0 2023-01-01   6   주말        1\n",
            "1 2023-01-02   0   주중        0\n",
            "2 2023-01-03   1   주중        0\n",
            "3 2023-01-04   2   주중        0\n",
            "4 2023-01-05   3   주중        0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 데이터를 날짜순으로 정렬 (과거 평균을 구하기 위해 필수)\n",
        "train = train.sort_values('영업일자')\n",
        "\n",
        "# 2. 월요일 데이터만 추출해서 '누적 과거 평균' 계산\n",
        "mon_data = train[train['요일'] == 0].copy()\n",
        "# expanding().mean()은 현재 행 이전까지의 모든 데이터 평균을 구합니다.\n",
        "# 단, 현재 날짜의 매출이 포함되지 않게 shift(1)을 해줍니다.\n",
        "mon_data['past_mon_mean'] = mon_data['매출수량'].expanding().mean().shift(1)\n",
        "\n",
        "# 3. 원본 데이터에 과거 평균값 합치기\n",
        "train = pd.merge(train, mon_data[['영업일자', 'past_mon_mean']], on='영업일자', how='left')\n",
        "\n",
        "# 4. 지수 계산: (현재 매출) / (과거 월요일들의 평균)\n",
        "# 첫 번째 월요일은 과거 데이터가 없으므로 결측치가 생길 수 있어 fillna(1) 처리\n",
        "train['mon_event_intensity'] = (train['매출수량'] / train['past_mon_mean']).fillna(1.0)\n",
        "\n",
        "# 확인\n",
        "print(train[train['요일']==0][['영업일자', '매출수량', 'past_mon_mean', 'mon_event_intensity']].head())\n",
        "\n",
        "\n",
        "\n",
        "# 월별 메뉴별 총 판매량 집계부터\n",
        "train_clean = train[train['매출수량'] >= 0].copy()\n",
        "monthly_agg = train_clean.groupby(['연도', '월', '영업장명', '메뉴명'])['매출수량'].sum().reset_index()\n",
        "monthly_agg.rename(columns={'매출수량': '월간_메뉴_총판매량'}, inplace=True)\n",
        "\n",
        "# 월별 전체 판매량 계산 후 구성비 계산\n",
        "total_monthly_sales = monthly_agg.groupby(['연도', '월', '영업장명'])['월간_메뉴_총판매량'].transform('sum')\n",
        "monthly_agg['메뉴_비중'] = monthly_agg['월간_메뉴_총판매량'] / total_monthly_sales\n",
        "\n",
        "# 월별 판매 순위 생성\n",
        "# 동일할 경우 'min' 방식으로 매김\n",
        "monthly_agg['메뉴_판매순위'] = monthly_agg.groupby(['연도', '월', '영업장명'])['월간_메뉴_총판매량'].rank(ascending=False, method='min')\n",
        "\n",
        "# 전월 대비 구성비의 증감폭\n",
        "# 메뉴별로 시계열 순서에 따라 이전 행과의 차이 계산\n",
        "monthly_agg = monthly_agg.sort_values(['영업장명', '메뉴명', '연도', '월'])\n",
        "monthly_agg['비중_증감폭'] = monthly_agg.groupby(['영업장명', '메뉴명'])['메뉴_비중'].diff().fillna(0)\n",
        "\n",
        "\n",
        "# 기존 데이터프레임에 결합\n",
        "# '영업장명'과 '메뉴명'을 키로 각 일자별 데이터에 매칭\n",
        "train_clean = train[train['매출수량'] >= 0].copy()\n",
        "df_final = pd.merge(train_clean,\n",
        "                    monthly_agg[['연도', '월', '영업장명', '메뉴명', '메뉴_비중', '메뉴_판매순위', '비중_증감폭']],\n",
        "                    on=['연도', '월', '영업장명', '메뉴명'], how='left')\n",
        "\n",
        "\n",
        "def add_detailed_off_status(df, window=7):\n",
        "    # 분석의 정확성을 위해 날짜순 정렬\n",
        "    df = df.sort_values(['영업장명', '영업일자'])\n",
        "    df['휴점여부'] = 0\n",
        "\n",
        "    # 영업장별로 루프를 돌며 판단 (해당 영업장이 문 닫으면 모든 메뉴 판매량이 0이 될 것을 가정함)\n",
        "    for shop in df['영업장명'].unique():\n",
        "        # 해당 영업장의 일자별 총 매출 수량 계산\n",
        "        shop_daily = df[df['영업장명'] == shop].groupby('영업일자')['매출수량'].sum().reset_index()\n",
        "\n",
        "        # window 기간 동안 매출 합계가 0인지 확인\n",
        "        is_zero = shop_daily['매출수량'] == 0\n",
        "        rolling_zero = is_zero.rolling(window=window).sum() == window\n",
        "\n",
        "        # 휴점으로 판단된 날짜들 추출\n",
        "        off_dates = shop_daily.loc[rolling_zero, '영업일자']\n",
        "\n",
        "        # 원본 데이터프레임에 반영 - 특정 날짜에 해당 영업장의 모든 메뉴 행을 휴점으로 표시\n",
        "        for off_date in off_dates:\n",
        "            # rolling이 끝나는 지점부터 역으로 window만큼 휴점 처리\n",
        "            start_date = off_date - pd.Timedelta(days=window-1)\n",
        "            mask = (df['영업장명'] == shop) & (df['영업일자'] >= start_date) & (df['영업일자'] <= off_date)\n",
        "            df.loc[mask, '휴점여부'] = 1\n",
        "\n",
        "    return df\n",
        "\n",
        "# 적용\n",
        "df_final = add_detailed_off_status(df_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ru4A6KBPQn-j",
        "outputId": "324e14ea-da1b-4bde-d906-5b21d1c0a9f3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          영업일자  매출수량  past_mon_mean  mon_event_intensity\n",
            "193 2023-01-02    17            NaN             1.000000\n",
            "194 2023-01-02    17      17.000000             1.000000\n",
            "195 2023-01-02    17       8.500000             2.000000\n",
            "196 2023-01-02    17       5.666667             3.000000\n",
            "197 2023-01-02    17       4.500000             3.777778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 업장 유형 파생변수 생성(범주형)\n",
        "flow_stores = ['포레스트릿', '화담숲주막', '화담숲카페', '카페테리아']\n",
        "\n",
        "train['store_type'] = np.where(\n",
        "    train['영업장명'].isin(flow_stores),\n",
        "    'flow',      # 유동형\n",
        "    'normal'     # 일반 식음\n",
        ")\n",
        "\n",
        "# 타깃 변환\n",
        "train['매출수량_log1p'] = np.log1p(train['매출수량'])\n",
        "\n",
        "# 메뉴 활동성\n",
        "menu_sell_rate = (\n",
        "    train.groupby(['영업장명','메뉴명'])['매출수량']\n",
        "         .apply(lambda x: (x > 0).mean())\n",
        "         .reset_index(name='sell_rate')\n",
        ")\n",
        "\n",
        "train = train.merge(menu_sell_rate, on=['영업장명','메뉴명'], how='left')\n",
        "\n",
        "# 메뉴X업장 기준 lag 변수\n",
        "group_cols = ['영업장명', '메뉴명']\n",
        "target = '매출수량'\n",
        "\n",
        "for lag in [1, 7, 14]:\n",
        "    train[f'lag_{lag}'] = (\n",
        "        train\n",
        "        .groupby(group_cols)[target]\n",
        "        .shift(lag)\n",
        "    )\n",
        "\n",
        "# 단기 노이즈 제거 + 추세 반영\n",
        "# Rolling 평균\n",
        "for win in [3, 7, 14]:\n",
        "    train[f'roll_{win}_mean'] = (\n",
        "        train\n",
        "        .groupby(group_cols)[target]\n",
        "        .shift(1)\n",
        "        .rolling(win)\n",
        "        .mean()\n",
        "    )\n",
        "\n",
        "# Rolling 표준편차\n",
        "train['roll_7_std'] = (\n",
        "    train\n",
        "    .groupby(group_cols)[target]\n",
        "    .shift(1)\n",
        "    .rolling(7)\n",
        "    .std()\n",
        ")\n",
        "\n",
        "# 스파이크 감지(지난주 대비 증감)\n",
        "train['diff_1'] = train['lag_1'] - train['lag_7']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkFjk_1HPcMq",
        "outputId": "9f991b27-9687-48d7-f2c6-2bcbb5b33649"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log1p\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def preprocess_menu_data(train: pd.DataFrame):\n",
        "    train = train.copy()\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 메뉴 카테고리화\n",
        "    def categorize_menu(name):\n",
        "        name = str(name).lower().replace(\" \", \"\")\n",
        "\n",
        "        categories = {\n",
        "            '행사/단체': ['단체', '연회', 'conference', 'ballroom', 'convention', 'opus', 'hall', 'platter', '패키지', '세트', 'openfood', '오픈푸드', '무제한', '뷔페', '정식'],\n",
        "            '대여/공간': ['대여', '이용료', '렌탈', '의자', '룸', '잔디그늘집'],\n",
        "            '주류': ['소주', '맥주', '와인', '막걸리', '하이볼', '칵테일', '카스', '테라', '참이슬', '처음처럼', '하이네켄', '버드와이저', '스텔라', '복분자', 'beer', 'wine', 'gls', 'bottle', '샷'],\n",
        "            '음료/카페': ['아메리카노', '라떼', '에이드', '주스', '식혜', '차', '커피', '티', '콜라', '사이다', '스프라이트', '미숫가루', '생수', '토닉', 'coffee'],\n",
        "            '구이/BBQ': ['bbq', '삼겹', '구이', '갈비', '목살', '양갈비', '한우', '등심', '스테이크', 'aus', '돈육', '소세지', '킬바사'],\n",
        "            '면류': ['파스타', '스파게티', '짜장', '짬뽕', '우동', '국수', '냉면', '라면', '소바', '알리오', '까르보나라', '메밀'],\n",
        "            '국/탕/찌개': ['찌개', '탕', '국밥', '전골', '해장국', '설렁탕', '갱시기', '육개장', '미역국'],\n",
        "            '분식/튀김': ['떡볶이', '튀김', '돈까스', '핫도그', '치킨', '너겟', '어묵', '순대'],\n",
        "            '밥류/한식': ['비빔밥', '덮밥', '볶음밥', '리조또', '공깃밥', '햇반', '주먹밥', '김치', '된장', '반찬'],\n",
        "            '디저트': ['아이스크림', '케이크', '쿠키', '빵', '와플', '빙수', '디저트', '푸딩'],\n",
        "            '소모품/기타': ['컵', '종이컵', '수저', '젓가락', '접시', '일회용', '가위', '집게', '부탄가스', '쌈장', '소스', '사리', '야채추가']\n",
        "        }\n",
        "\n",
        "        for cat, keywords in categories.items():\n",
        "            for kw in keywords:\n",
        "                if kw in name:\n",
        "                    return cat\n",
        "        return '기타'\n",
        "\n",
        "    train['메뉴_카테고리'] = train['메뉴명'].apply(categorize_menu)\n",
        "    return train\n",
        "\n",
        "def encode_features_train_only(train: pd.DataFrame):\n",
        "    train = train.copy()\n",
        "\n",
        "    le_store = LabelEncoder()\n",
        "    le_menu = LabelEncoder()\n",
        "    le_cat = LabelEncoder()\n",
        "\n",
        "    # Train 데이터에 대해서만 fit_transform 수행\n",
        "    train['영업장명_le'] = le_store.fit_transform(train['영업장명'].astype(str))\n",
        "    train['메뉴명_le'] = le_menu.fit_transform(train['메뉴명'].astype(str))\n",
        "    train['카테고리_le'] = le_cat.fit_transform(train['메뉴_카테고리'].astype(str))\n",
        "\n",
        "    return train, le_store, le_menu, le_cat\n",
        "\n",
        "\n",
        "# 전처리 수행\n",
        "train = preprocess_menu_data(train)\n",
        "\n",
        "# 인코딩\n",
        "train_encoded, le_store, le_menu, le_cat = encode_features_train_only(train)"
      ],
      "metadata": {
        "id": "pYxo7KqNQYj-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결과\n",
        "print(train_encoded[['영업장명_메뉴명', '영업장명', '메뉴명', '메뉴_카테고리', '카테고리_le']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7roM0vDQhXa",
        "outputId": "f2d5b1a4-7fe4-4180-9612-523ba27fa34e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             영업장명_메뉴명        영업장명            메뉴명 메뉴_카테고리  카테고리_le\n",
            "0  느티나무 셀프BBQ_1인 수저세트  느티나무 셀프BBQ        1인 수저세트   행사/단체       11\n",
            "1   연회장_Conference M8         연회장  Conference M8   행사/단체       11\n",
            "2        미라시아_핑크레몬에이드        미라시아        핑크레몬에이드   음료/카페        9\n",
            "3  라그로타_미션 서드 카베르네 쉬라        라그로타  미션 서드 카베르네 쉬라      기타        2\n",
            "4          화담숲주막_병천순대       화담숲주막           병천순대   분식/튀김        7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 제미나이가 통합본 정리해준 전처리 코드들"
      ],
      "metadata": {
        "id": "8HNYqv8DXczJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# =========================================================\n",
        "# 1. 함수 정의 (전처리용 헬퍼 함수들)\n",
        "# =========================================================\n",
        "\n",
        "def categorize_menu(name):\n",
        "    \"\"\"메뉴명을 기반으로 카테고리를 분류하는 함수\"\"\"\n",
        "    name = str(name).lower().replace(\" \", \"\")\n",
        "\n",
        "    categories = {\n",
        "        '행사/단체': ['단체', '연회', 'conference', 'ballroom', 'convention', 'opus', 'hall', 'platter', '패키지', '세트', 'openfood', '오픈푸드', '무제한', '뷔페', '정식'],\n",
        "        '대여/공간': ['대여', '이용료', '렌탈', '의자', '룸', '잔디그늘집'],\n",
        "        '주류': ['소주', '맥주', '와인', '막걸리', '하이볼', '칵테일', '카스', '테라', '참이슬', '처음처럼', '하이네켄', '버드와이저', '스텔라', '복분자', 'beer', 'wine', 'gls', 'bottle', '샷'],\n",
        "        '음료/카페': ['아메리카노', '라떼', '에이드', '주스', '식혜', '차', '커피', '티', '콜라', '사이다', '스프라이트', '미숫가루', '생수', '토닉', 'coffee'],\n",
        "        '구이/BBQ': ['bbq', '삼겹', '구이', '갈비', '목살', '양갈비', '한우', '등심', '스테이크', 'aus', '돈육', '소세지', '킬바사'],\n",
        "        '면류': ['파스타', '스파게티', '짜장', '짬뽕', '우동', '국수', '냉면', '라면', '소바', '알리오', '까르보나라', '메밀'],\n",
        "        '국/탕/찌개': ['찌개', '탕', '국밥', '전골', '해장국', '설렁탕', '갱시기', '육개장', '미역국'],\n",
        "        '분식/튀김': ['떡볶이', '튀김', '돈까스', '핫도그', '치킨', '너겟', '어묵', '순대'],\n",
        "        '밥류/한식': ['비빔밥', '덮밥', '볶음밥', '리조또', '공깃밥', '햇반', '주먹밥', '김치', '된장', '반찬'],\n",
        "        '디저트': ['아이스크림', '케이크', '쿠키', '빵', '와플', '빙수', '디저트', '푸딩'],\n",
        "        '소모품/기타': ['컵', '종이컵', '수저', '젓가락', '접시', '일회용', '가위', '집게', '부탄가스', '쌈장', '소스', '사리', '야채추가']\n",
        "    }\n",
        "\n",
        "    for cat, keywords in categories.items():\n",
        "        for kw in keywords:\n",
        "            if kw in name:\n",
        "                return cat\n",
        "    return '기타'\n",
        "\n",
        "def add_detailed_off_status(df, window=7):\n",
        "    \"\"\"7일 연속 매출 0인 경우 휴점으로 판단\"\"\"\n",
        "    df = df.copy()\n",
        "    # 날짜순 정렬 필수\n",
        "    df = df.sort_values(['영업장명', '영업일자'])\n",
        "    df['휴점여부'] = 0\n",
        "\n",
        "    for shop in df['영업장명'].unique():\n",
        "        shop_mask = df['영업장명'] == shop\n",
        "        shop_daily = df[shop_mask].groupby('영업일자')['매출수량'].sum().reset_index()\n",
        "\n",
        "        is_zero = shop_daily['매출수량'] == 0\n",
        "        rolling_zero = is_zero.rolling(window=window).sum() == window\n",
        "        off_dates = shop_daily.loc[rolling_zero, '영업일자']\n",
        "\n",
        "        for off_date in off_dates:\n",
        "            start_date = off_date - pd.Timedelta(days=window-1)\n",
        "            # 해당 기간 마스킹\n",
        "            mask = (df['영업장명'] == shop) & (df['영업일자'] >= start_date) & (df['영업일자'] <= off_date)\n",
        "            df.loc[mask, '휴점여부'] = 1\n",
        "\n",
        "    return df\n",
        "\n",
        "def encode_features_train_only(train_df):\n",
        "    \"\"\"라벨 인코딩 수행\"\"\"\n",
        "    df = train_df.copy()\n",
        "    le_store = LabelEncoder()\n",
        "    le_menu = LabelEncoder()\n",
        "    le_cat = LabelEncoder()\n",
        "\n",
        "    df['영업장명_le'] = le_store.fit_transform(df['영업장명'].astype(str))\n",
        "    df['메뉴명_le'] = le_menu.fit_transform(df['메뉴명'].astype(str))\n",
        "    df['카테고리_le'] = le_cat.fit_transform(df['메뉴_카테고리'].astype(str))\n",
        "\n",
        "    return df, le_store, le_menu, le_cat\n",
        "\n",
        "# =========================================================\n",
        "# 2. 메인 전처리 실행\n",
        "# =========================================================\n",
        "\n",
        "# 1) 데이터 로드\n",
        "train = pd.read_csv('train.csv')\n",
        "\n",
        "# 2) 텍스트 정제 및 업장/메뉴명 분리\n",
        "train['영업장명_메뉴명'] = train['영업장명_메뉴명'].astype(str).str.replace(r\"\\ufeff|\\u200b\", \"\", regex=True)\n",
        "train['영업장명_메뉴명'] = train['영업장명_메뉴명'].str.replace(\"\\xa0\", \" \", regex=False).str.strip()\n",
        "split_data = train['영업장명_메뉴명'].str.split('_', n=1, expand=True)\n",
        "train['영업장명'] = split_data[0].str.strip()\n",
        "train['메뉴명'] = split_data[1].str.strip() if split_data.shape[1] > 1 else \"미상\"\n",
        "\n",
        "# 3) 날짜 형식 변환 및 기본 날짜 피처\n",
        "train['영업일자'] = pd.to_datetime(train['영업일자'])\n",
        "train['연도'] = train['영업일자'].dt.year\n",
        "train['월'] = train['영업일자'].dt.month\n",
        "train['일'] = train['영업일자'].dt.day\n",
        "train['요일'] = train['영업일자'].dt.dayofweek\n",
        "train['주'] = train['영업일자'].dt.isocalendar().week.astype(int)\n",
        "\n",
        "# 4) 공휴일 및 주말 정보 생성\n",
        "train['주말여부'] = (train['요일'] >= 4).map({True: '주말', False: '주중'})\n",
        "\n",
        "holis = ['01-01', '03-01', '05-05', '06-06', '08-15', '10-03', '10-09', '12-25']\n",
        "lunar_holidays = ['2023-01-21', '2023-01-22', '2023-01-23', '2023-09-28', '2023-09-29', '2023-09-30', '2024-02-09', '2024-02-10', '2024-02-11']\n",
        "substitute_holidays = ['2023-01-24', '2023-05-29', '2023-10-02', '2024-02-12', '2024-04-10', '2024-05-06']\n",
        "\n",
        "train['공휴일여부'] = train['영업일자'].dt.strftime('%m-%d').isin(holis).astype(int)\n",
        "train['음력공휴일여부'] = train['영업일자'].dt.strftime('%Y-%m-%d').isin(lunar_holidays).astype(int)\n",
        "train['대체공휴일여부'] = train['영업일자'].dt.strftime('%Y-%m-%d').isin(substitute_holidays).astype(int)\n",
        "train['전체공휴일여부'] = ((train['공휴일여부'] == 1) | (train['음력공휴일여부'] == 1) | (train['대체공휴일여부'] == 1)).astype(int)\n",
        "\n",
        "# 5) 정렬 (시계열 연산을 위해 필수)\n",
        "train = train.sort_values(['영업장명', '메뉴명', '영업일자'])\n",
        "\n",
        "# 6) 월요일 과거 평균 (Expanding Mean)\n",
        "mon_data = train[train['요일'] == 0].copy()\n",
        "mon_data['past_mon_mean'] = mon_data.groupby(['영업장명', '메뉴명'])['매출수량'].expanding().mean().shift(1).reset_index(level=[0,1], drop=True)\n",
        "train = pd.merge(train, mon_data[['영업일자', '영업장명', '메뉴명', 'past_mon_mean']], on=['영업일자', '영업장명', '메뉴명'], how='left')\n",
        "train['mon_event_intensity'] = (train['매출수량'] / train['past_mon_mean']).fillna(1.0)\n",
        "\n",
        "# 7) 월별 집계 통계 (비중, 순위 등)\n",
        "# 주의: 원본 코드의 로직을 유지하되, train 데이터프레임에 병합\n",
        "monthly_agg = train.groupby(['연도', '월', '영업장명', '메뉴명'])['매출수량'].sum().reset_index()\n",
        "monthly_agg.rename(columns={'매출수량': '월간_메뉴_총판매량'}, inplace=True)\n",
        "total_monthly_sales = monthly_agg.groupby(['연도', '월', '영업장명'])['월간_메뉴_총판매량'].transform('sum')\n",
        "monthly_agg['메뉴_비중'] = monthly_agg['월간_메뉴_총판매량'] / (total_monthly_sales + 1e-9) # 0나누기 방지\n",
        "monthly_agg['메뉴_판매순위'] = monthly_agg.groupby(['연도', '월', '영업장명'])['월간_메뉴_총판매량'].rank(ascending=False, method='min')\n",
        "monthly_agg = monthly_agg.sort_values(['영업장명', '메뉴명', '연도', '월'])\n",
        "monthly_agg['비중_증감폭'] = monthly_agg.groupby(['영업장명', '메뉴명'])['메뉴_비중'].diff().fillna(0)\n",
        "\n",
        "train = pd.merge(train, monthly_agg[['연도', '월', '영업장명', '메뉴명', '메뉴_비중', '메뉴_판매순위', '비중_증감폭']],\n",
        "                 on=['연도', '월', '영업장명', '메뉴명'], how='left')\n",
        "\n",
        "# 8) 휴점 여부 및 업장 타입\n",
        "train = add_detailed_off_status(train)\n",
        "flow_stores = ['포레스트릿', '화담숲주막', '화담숲카페', '카페테리아']\n",
        "train['store_type'] = np.where(train['영업장명'].isin(flow_stores), 'flow', 'normal')\n",
        "\n",
        "# 9) 메뉴 카테고리 및 활동성 지표\n",
        "train['메뉴_카테고리'] = train['메뉴명'].apply(categorize_menu)\n",
        "train['매출수량_log1p'] = np.log1p(train['매출수량'])\n",
        "\n",
        "menu_sell_rate = train.groupby(['영업장명','메뉴명'])['매출수량'].apply(lambda x: (x > 0).mean()).reset_index(name='sell_rate')\n",
        "train = train.merge(menu_sell_rate, on=['영업장명','메뉴명'], how='left')\n",
        "\n",
        "# 10) 시계열 Lag 및 Rolling 변수 (다시 정렬 후 수행)\n",
        "train = train.sort_values(['영업장명', '메뉴명', '영업일자'])\n",
        "group_cols = ['영업장명', '메뉴명']\n",
        "target = '매출수량'\n",
        "\n",
        "for lag in [1, 7, 14]:\n",
        "    train[f'lag_{lag}'] = train.groupby(group_cols)[target].shift(lag)\n",
        "\n",
        "for win in [3, 7, 14]:\n",
        "    train[f'roll_{win}_mean'] = train.groupby(group_cols)[target].shift(1).rolling(win).mean()\n",
        "\n",
        "train['roll_7_std'] = train.groupby(group_cols)[target].shift(1).rolling(7).std()\n",
        "train['diff_1'] = train['lag_1'] - train['lag_7']\n",
        "\n",
        "# 11) 결측치 처리 (Lag로 인한 NaN 채우기)\n",
        "train = train.fillna(0)\n",
        "\n",
        "# 12) 라벨 인코딩 (최종)\n",
        "train_encoded, le_store, le_menu, le_cat = encode_features_train_only(train)\n",
        "\n",
        "# 결과 확인\n",
        "print(\"전처리 완료! 데이터 크기:\", train_encoded.shape)\n",
        "print(train_encoded[['영업일자', '영업장명', '메뉴명', '휴점여부', '매출수량_log1p', '카테고리_le']].head())"
      ],
      "metadata": {
        "id": "daeTwrTzXfOi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5669f3b4-344b-4dc2-a1fc-8a79ee8e2657"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log1p\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리 완료! 데이터 크기: (102676, 36)\n",
            "         영업일자        영업장명      메뉴명  휴점여부  매출수량_log1p  카테고리_le\n",
            "0  2023-01-01  느티나무 셀프BBQ  1인 수저세트     0         0.0       11\n",
            "23 2023-01-02  느티나무 셀프BBQ  1인 수저세트     0         0.0       11\n",
            "46 2023-01-03  느티나무 셀프BBQ  1인 수저세트     0         0.0       11\n",
            "69 2023-01-04  느티나무 셀프BBQ  1인 수저세트     0         0.0       11\n",
            "92 2023-01-05  느티나무 셀프BBQ  1인 수저세트     0         0.0       11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_encoded.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17VfEA7F1EjI",
        "outputId": "f93aa7dd-65b0-42c9-c7bf-3f71389ba7df"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 102676 entries, 0 to 102675\n",
            "Data columns (total 36 columns):\n",
            " #   Column               Non-Null Count   Dtype         \n",
            "---  ------               --------------   -----         \n",
            " 0   영업일자                 102676 non-null  datetime64[ns]\n",
            " 1   영업장명_메뉴명             102676 non-null  object        \n",
            " 2   매출수량                 102676 non-null  int64         \n",
            " 3   영업장명                 102676 non-null  object        \n",
            " 4   메뉴명                  102676 non-null  object        \n",
            " 5   연도                   102676 non-null  int32         \n",
            " 6   월                    102676 non-null  int32         \n",
            " 7   일                    102676 non-null  int32         \n",
            " 8   요일                   102676 non-null  int32         \n",
            " 9   주                    102676 non-null  int64         \n",
            " 10  주말여부                 102676 non-null  object        \n",
            " 11  공휴일여부                102676 non-null  int64         \n",
            " 12  음력공휴일여부              102676 non-null  int64         \n",
            " 13  대체공휴일여부              102676 non-null  int64         \n",
            " 14  전체공휴일여부              102676 non-null  int64         \n",
            " 15  past_mon_mean        102676 non-null  float64       \n",
            " 16  mon_event_intensity  102676 non-null  float64       \n",
            " 17  메뉴_비중                102676 non-null  float64       \n",
            " 18  메뉴_판매순위              102676 non-null  float64       \n",
            " 19  비중_증감폭               102676 non-null  float64       \n",
            " 20  휴점여부                 102676 non-null  int64         \n",
            " 21  store_type           102676 non-null  object        \n",
            " 22  메뉴_카테고리              102676 non-null  object        \n",
            " 23  매출수량_log1p           102676 non-null  float64       \n",
            " 24  sell_rate            102676 non-null  float64       \n",
            " 25  lag_1                102676 non-null  float64       \n",
            " 26  lag_7                102676 non-null  float64       \n",
            " 27  lag_14               102676 non-null  float64       \n",
            " 28  roll_3_mean          102676 non-null  float64       \n",
            " 29  roll_7_mean          102676 non-null  float64       \n",
            " 30  roll_14_mean         102676 non-null  float64       \n",
            " 31  roll_7_std           102676 non-null  float64       \n",
            " 32  diff_1               102676 non-null  float64       \n",
            " 33  영업장명_le              102676 non-null  int64         \n",
            " 34  메뉴명_le               102676 non-null  int64         \n",
            " 35  카테고리_le              102676 non-null  int64         \n",
            "dtypes: datetime64[ns](1), float64(15), int32(4), int64(10), object(6)\n",
            "memory usage: 27.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 단일모델 모델링\n",
        "LGBM, XGBoost + CatBoost(?)\n",
        "\n",
        "## LGBM\n",
        "\n",
        "##XGBoost"
      ],
      "metadata": {
        "id": "5AfoRRIM1OMn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5A3i6DWh1HaQ"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}